{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['author', ' \"url\"'], ['yoshikawa', ' http://www.aozora.gr.jp/index_pages/person1562.html#sakuhin_list_1']]\n"
     ]
    }
   ],
   "source": [
    "from urllib.request import urlopen\n",
    "import urllib.request\n",
    "import urllib\n",
    "from urllib.error import URLError, HTTPError\n",
    "from bs4 import BeautifulSoup\n",
    "import sys, os.path, re, csv\n",
    "import pandas as pds\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import codecs\n",
    "import zipfile\n",
    "\n",
    "# Defining url of Aozora-bunko and local work directory.\n",
    "base_url = \"http://www.aozora.gr.jp/\"\n",
    "data_dir = \"./\"\n",
    "aozora_dir = data_dir + \"aozora_data/\"\n",
    "log_dir = aozora_dir + \"log/\"\n",
    "\n",
    "# The project uses csv with the name of author and his/her url in Aozora-bunko\n",
    "target_author_file = data_dir + \"target_author.csv\"\n",
    "\n",
    "auth_target = []\n",
    "with open(target_author_file,\"r\") as f:\n",
    "    reader = csv.reader(f)\n",
    "    for row in reader:\n",
    "        auth_target.append(row)\n",
    "auth_target\n",
    "\n",
    "print (auth_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Make directories for authors and csv, text extraction, and utf converted directories for them.\n",
    "\n",
    "def make_workdir(aozora_dir=aozora_dir, auth_target=auth_target):\n",
    "    if not os.path.exists(aozora_dir):\n",
    "        try:\n",
    "            os.makedirs(aozora_dir)\n",
    "            print (\"make: \" + aozora_dir)\n",
    "        except OSError as e:\n",
    "            print (e)\n",
    "            \n",
    "    if not os.path.exists(log_dir):\n",
    "        try:\n",
    "            os.makedirs(log_dir)\n",
    "            print (\"make: \" + log_dir)\n",
    "        except OSError as e:\n",
    "            print (e)\n",
    "        \n",
    "    for w in auth_target[1:]:\n",
    "        auth_dir = '{}{}/'.format(aozora_dir, w[0])\n",
    "        if not os.path.exists(auth_dir):\n",
    "            try:\n",
    "                os.makedirs(auth_dir)\n",
    "                print (\"make: \" + auth_dir)\n",
    "            except OSError as e:\n",
    "                print (e)\n",
    "        if not os.path.exists(auth_dir + \"csv/\"):\n",
    "            try:\n",
    "                os.makedirs(auth_dir + \"csv/\")\n",
    "                print (\"make: \" + auth_dir + \"csv/\")\n",
    "            except OSError as e:\n",
    "                print (e)\n",
    "        if not os.path.exists(auth_dir + \"ext/\"):\n",
    "            try:\n",
    "                os.makedirs(auth_dir + \"ext/\")\n",
    "                print (\"make: \" + auth_dir + \"ext/\")\n",
    "            except OSError as e:\n",
    "                print (e)\n",
    "        if not os.path.exists(auth_dir + \"utf/\"):\n",
    "            try:\n",
    "                os.makedirs(auth_dir + \"utf/\")\n",
    "                print (\"make: \" + auth_dir + \"utf/\")\n",
    "            except OSError as e:\n",
    "                print (e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Downloads all the zip files from author's written pieces.\n",
    "\n",
    "def download_zip(auth_target=auth_target):\n",
    "    for w in auth_target[1:]:\n",
    "        print (\"starting %s\" % w[0])\n",
    "        auth_dir = '{}{}/'.format(aozora_dir, w[0])\n",
    "        url = w[1]\n",
    "        \n",
    "        html = urlopen(url)\n",
    "\n",
    "        if html.getcode() == 200:\n",
    "            soup = BeautifulSoup(html, \"lxml\")\n",
    "            piece_list = soup.find(\"ol\")\n",
    "            piece_links = piece_list.find_all(\"a\")\n",
    "            piece_links_np = np.array([[\"datetime\",\"title\",\"url\",\"zip\"]])\n",
    "            for i in piece_links:\n",
    "                title = i.string\n",
    "                link = base_url + i[\"href\"].replace(\"../\", \"\")\n",
    "                if \"cards\" in link:\n",
    "                    print (\"    piece: %s for %s\" % (title, link))\n",
    "                    piece_html = urlopen(link)\n",
    "                    if piece_html.getcode() == 200:\n",
    "                        soup = BeautifulSoup(piece_html, \"lxml\")\n",
    "                        zip_part = soup.find_all(\"a\", href=re.compile(\".zip\"))\n",
    "                        if zip_part != []:\n",
    "                            zip_file = zip_part[0][\"href\"]\n",
    "                            zip_url = urllib.parse.urljoin(link, zip_file)\n",
    "                            print (\"        zip_url: %s\" % zip_url)\n",
    "                            now = datetime.now().strftime(\"%Y/%m/%d %H:%M:%S\")\n",
    "                            tmp = np.array([[now, title, link, zip_url]])\n",
    "                            piece_links_np = np.vstack((piece_links_np, tmp))\n",
    "\n",
    "                            file_name = os.path.basename(zip_url)\n",
    "                            file_full_path = '{}{}'.format(auth_dir, file_name)\n",
    "                            urllib.request.urlretrieve(zip_url, filename=file_full_path)\n",
    "\n",
    "            piece_links_pds = pds.DataFrame(piece_links_np[1:,:], columns=piece_links_np[0,:])\n",
    "            piece_links_pds.to_csv(log_dir + w[0] + '_dl_log.csv', quoting=csv.QUOTE_ALL)\n",
    "        print (\"finished %s\" % w[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Extract zip files to txt files. Its character encoding is in SHIfT-JIS.\n",
    "\n",
    "def zip_extract(auth_target=auth_target):\n",
    "    log_np = np.array([[\"datetime\", \"author\", \"zip\"]])\n",
    "    for w in auth_target[1:]:\n",
    "        auth_dir = '{}{}/'.format(aozora_dir, w[0])\n",
    "        ext_dir = '{}{}'.format(auth_dir, \"ext/\")\n",
    "        files = os.listdir(auth_dir)\n",
    "        for file in files:\n",
    "            if \"zip\" in file:\n",
    "                file_fullpath = auth_dir + file\n",
    "                with zipfile.ZipFile(file_fullpath, 'r') as zip_file:\n",
    "                    zip_file.extractall(path=ext_dir)\n",
    "                    now = datetime.now().strftime(\"%Y/%m/%d %H:%M:%S\")\n",
    "                    tmp = np.array([[now, w[0], zip_file]])\n",
    "                    log_np = np.vstack((log_np, tmp))\n",
    "                    print (\"extracted: \" + str(zip_file))\n",
    "        zip_ext_pds = pds.DataFrame(log_np[1:,:], columns=log_np[0,:])\n",
    "        zip_ext_pds.to_csv(log_dir + w[0] + '_zip_log.csv', quoting=csv.QUOTE_ALL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Making txt files with SHIFT-JIS converted to UTF-8.\n",
    "\n",
    "def convert_sjis_to_utf8(auth_target=auth_target):\n",
    "    log_np = np.array([[\"datetime\", \"author\", \"file\"]])\n",
    "    for w in auth_target[1:]:\n",
    "        auth_dir = '{}{}/'.format(aozora_dir, w[0])\n",
    "        ext_dir = '{}{}'.format(auth_dir, \"ext/\")\n",
    "        utf_dir = '{}{}'.format(auth_dir, \"utf/\")\n",
    "        files = os.listdir(ext_dir)\n",
    "        for file in files:\n",
    "            if \"txt\" in file:\n",
    "                file_name = ext_dir + file\n",
    "                save_name = utf_dir + file\n",
    "                fout = codecs.open(file_name, 'r', 'shift_jis')\n",
    "                fsave = codecs.open(save_name, 'w+', 'utf-8')\n",
    "                try:\n",
    "                    for row in fout:\n",
    "                        fsave.write(row)\n",
    "                except Exception as e:\n",
    "                    print (file + \"gets exception: \" + str(type(e)))\n",
    "                finally:\n",
    "                    fout.close()\n",
    "                    fsave.close()\n",
    "                    print (\"converted: \" + save_name)      \n",
    "                    now = datetime.now().strftime(\"%Y/%m/%d %H:%M:%S\")\n",
    "                    tmp = np.array([[now, w[0], file]])\n",
    "                    log_np = np.vstack((log_np, tmp))              \n",
    "        convert_pds = pds.DataFrame(log_np[1:,:], columns=log_np[0,:])\n",
    "        convert_pds.to_csv(log_dir + w[0] + '_cvt_log.csv', quoting=csv.QUOTE_ALL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Cleansing UTF-8 texts and convert them to files to CSV.\n",
    "\n",
    "def data_cleanse(auth_target=auth_target):\n",
    "    for w in auth_target[1:]:\n",
    "        print (\"starting: \" + w[0])\n",
    "        auth_dir = '{}{}/'.format(aozora_dir, w[0])\n",
    "        ext_dir = '{}{}'.format(auth_dir, \"ext/\")\n",
    "        utf_dir = '{}{}'.format(auth_dir, \"utf/\")\n",
    "        csv_dir = '{}{}'.format(auth_dir, \"csv/\")\n",
    "        files = os.listdir(utf_dir)\n",
    "        for file in files:\n",
    "            if \"txt\" in file:\n",
    "                print (\"     file: \" + file)\n",
    "                file_name = utf_dir + file\n",
    "                np_lines = np.array([[\"auth\",\"piece\",\"line\"]])\n",
    "                f = open(file_name, 'r')\n",
    "\n",
    "                lines = f.read()\n",
    "                f.close\n",
    "                \n",
    "                lines = lines.replace(u'。', '。\\n')\n",
    "                lines = lines.split('\\n')\n",
    "\n",
    "                ruby = re.compile(u'\\《.+?\\》')\n",
    "                chuki = re.compile(u'\\［.+?\\］')\n",
    "                zen_sp = re.compile(u'　')\n",
    "                zen_sp2 = re.compile(u'\\u3000')\n",
    "\n",
    "                for line in lines:\n",
    "                    line_mod = ruby.sub(\"\", line)\n",
    "                    line_mod = chuki.sub(\"\", line_mod)\n",
    "                    line_mod = zen_sp.sub(\"\", line_mod)\n",
    "                    line_mod = zen_sp2.sub(\"\", line_mod)\n",
    "                    np_tmp = np.array([[w[0], file, line_mod]])\n",
    "                    np_lines = np.vstack((np_lines, np_tmp))\n",
    "\n",
    "                s_line = 1\n",
    "                e_line = len(lines)\n",
    "                np_lines_cut = np_lines[s_line:e_line,:]\n",
    "\n",
    "\n",
    "                file = file.replace(\".txt\", \"\")\n",
    "                lines_pds = pds.DataFrame(np_lines_cut, columns=np_lines[0,:])\n",
    "                lines_pds.to_csv(csv_dir + file + '.csv', quoting=csv.QUOTE_ALL)\n",
    "\n",
    "        print (\"finished: \" + w[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting: yoshikawa\n",
      "     file: ashi.txt\n",
      "     file: uesugikenshin.txt\n",
      "     file: utsukushii_nihonno_rekishi.txt\n",
      "     file: ume_chirahora.txt\n",
      "     file: edo_sangokushi.txt\n",
      "     file: ookaechizen.txt\n",
      "     file: otani_gyobu.txt\n",
      "     file: oshiire_zuihitsu.txt\n",
      "     file: otaka.txt\n",
      "     file: oni.txt\n",
      "     file: oriorino_ki.txt\n",
      "     file: kagaribino_onna.txt\n",
      "     file: gyomon.txt\n",
      "     file: ginga_matsuri.txt\n",
      "     file: kuse.txt\n",
      "     file: kumokiri_enmacho.txt\n",
      "     file: kuroda_josui.txt\n",
      "     file: keiba.txt\n",
      "     file: getobashi_yurai.txt\n",
      "     file: kennan_jonan.txt\n",
      "     file: 01jo_kenno_yonkunshi.txt\n",
      "     file: 02yagyu_sekishusai.txt\n",
      "     file: 03hayashizaki_jinsuke.txt\n",
      "     file: 04takahashi_deishu.txt\n",
      "     file: 05ono_tadaaki.txt\n",
      "     file: kobaino_kyaku.txt\n",
      "     file: 01jo.txt\n",
      "     file: 02toenno_maki.txt\n",
      "     file: 03gunseino_maki.txt\n",
      "     file: 04somono_maki.txt\n",
      "     file: 05shidono_maki.txt\n",
      "     file: 06komeino_maki.txt\n",
      "     file: 07sekihekino_maki.txt\n",
      "     file: 08boshokuno_maki.txt\n",
      "     file: 09tonanno_maki.txt\n",
      "     file: 10suishino_maki.txt\n",
      "     file: 11gojogenno_maki.txt\n",
      "     file: 12hengaiyoroku.txt\n",
      "     file: shitano_susabi.txt\n",
      "     file: jitenno_susume.txt\n",
      "     file: 01ashikaga_jo.txt\n",
      "     file: 02basara_jo.txt\n",
      "     file: 03minakami_jo.txt\n",
      "     file: 04teigoku_jo.txt\n",
      "     file: 05yono_tsujino_jo.txt\n",
      "     file: 06hakko_jo.txt\n",
      "     file: 07chihaya_jo.txt\n",
      "     file: 08nitta_jo.txt\n",
      "     file: 09kenmu_rakugaki_jo.txt\n",
      "     file: 10kazabana_jo.txt\n",
      "     file: 11tsukushi_jo.txt\n",
      "     file: 12minatogawa_jo.txt\n",
      "     file: 13kokubyaku_jo.txt\n",
      "     file: shosetsuno_tane.txt\n",
      "     file: shosointen'o_miru.txt\n",
      "     file: shoyu_botoke.txt\n",
      "     file: jirokichi_koshi.txt\n",
      "     file: shinsho_taikoki01.txt\n",
      "     file: shinsho_taikoki02.txt\n",
      "     file: shinsho_taikoki03.txt\n",
      "     file: shinsho_taikoki04.txt\n",
      "     file: shinsho_taikoki05.txt\n",
      "     file: shinsho_taikoki06.txt\n",
      "     file: shinsho_taikoki07.txt\n",
      "     file: shinsho_taikoki08.txt\n",
      "     file: shinsho_taikoki09.txt\n",
      "     file: shinsho_taikoki10.txt\n",
      "     file: shinsho_taikoki11.txt\n",
      "     file: shinda_chidori.txt\n",
      "     file: shinranshoninni_tsuite.txt\n",
      "     file: shinranno_suimyaku.txt\n",
      "     file: zuihitsu_shihon_taiheiki.txt\n",
      "     file: zuihitsu_shinheike.txt\n",
      "     file: zuihitsu_miyamoto_muasashi.txt\n",
      "     file: sesson_hitsu_nasuzu.txt\n",
      "     file: zocho_tenno.txt\n",
      "     file: zoku_soku_bodai.txt\n",
      "     file: tairanomasakado.txt\n",
      "     file: tazaki_sounto_sonoko.txt\n",
      "     file: chazuke_sanryaku.txt\n",
      "     file: tennoto_keiba.txt\n",
      "     file: natsumushi_andon.txt\n",
      "     file: nabeshima_kainokami.txt\n",
      "     file: narutohicho01.txt\n",
      "     file: narutohicho02.txt\n",
      "     file: narutohicho03.txt\n",
      "     file: narutohicho04.txt\n",
      "     file: narutohicho05.txt\n",
      "     file: narutohicho06.txt\n",
      "     file: onodera_junaino_tsuma.txt\n",
      "     file: shizuka_gozen.txt\n",
      "     file: taiko_fujin.txt\n",
      "     file: tani_tateki_fujin.txt\n",
      "     file: dainanko_fujin.txt\n",
      "     file: hosokawa_garasha_fujin.txt\n",
      "     file: ningen_sansui_zumaki.txt\n",
      "     file: nozuchino_hyaku.txt\n",
      "     file: baishino_tsue.txt\n",
      "     file: hataoka_junsa.txt\n",
      "     file: hakkan_dochu.txt\n",
      "     file: hanakami_ronin.txt\n",
      "     file: haruno_kari.txt\n",
      "     file: fugu.txt\n",
      "     file: bunkano_hi.txt\n",
      "     file: bengara_kotatsu.txt\n",
      "     file: minamotono_yoritomo.txt\n",
      "     file: 02chino_maki.txt\n",
      "     file: 03mizuno_maki.txt\n",
      "     file: 04hino_maki.txt\n",
      "     file: 05kazeno_maki.txt\n",
      "     file: 06sorano_maki.txt\n",
      "     file: 07nitenno_maki.txt\n",
      "     file: 08enmyono_maki.txt\n",
      "     file: mushuku_jinkokuki.txt\n",
      "     file: montsukio_kiruno_ki.txt\n",
      "     file: yagyu_tsukikage_sho.txt\n",
      "     file: yamaura_kiyomaro.txt\n",
      "     file: yugaono_mon.txt\n",
      "     file: rakujitsuno_sogonni_niru.txt\n",
      "     file: rogokuno_hanayome.txt\n",
      "finished: yoshikawa\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    make_workdir(aozora_dir, auth_target)\n",
    "    download_zip(auth_target)\n",
    "    zip_extract(auth_target)\n",
    "    convert_sjis_to_utf8(auth_target)\n",
    "    data_cleanse(auth_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished\n"
     ]
    }
   ],
   "source": [
    "print (\"finished\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
